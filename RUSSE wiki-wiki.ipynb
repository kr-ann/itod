{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\russe-wsi-kit\\\\data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = pandas.read_csv(path+\"main\\\\wiki-wiki\\\\train.csv\", \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "{'замок': {1, 2}, 'лук': {1, 2}, 'суда': {1, 2}, 'бор': {1, 2}}\n"
     ]
    }
   ],
   "source": [
    "# посмотрим на слова и на их набор значений\n",
    "words_dict = dict()\n",
    "\n",
    "for word in wiki_wiki[\"word\"]:\n",
    "    if word not in words_dict:\n",
    "        words_dict.setdefault(word, set())\n",
    "\n",
    "for target_word in words_dict:\n",
    "    for sense_id in wiki_wiki[wiki_wiki.word == target_word][\"gold_sense_id\"]:\n",
    "        words_dict[target_word].add(sense_id)\n",
    "\n",
    "print(len(words_dict))\n",
    "print(words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "замок\n",
      "лук\n",
      "суда\n",
      "бор\n"
     ]
    }
   ],
   "source": [
    "for word in words_dict:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[1, 2]\n",
      "[1, 2]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# преобразуем set'ы в листы, чтобы был определнённый порядок, и сортируем по возрастанию\n",
    "for word in words_dict:\n",
    "    words_dict[word] = sorted(list(words_dict[word]))\n",
    "    \n",
    "for word in words_dict:\n",
    "    print(words_dict[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "110\n",
      "135\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "for word in words_dict:\n",
    "    print(len(wiki_wiki[wiki_wiki.word == word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 38]\n",
      "[65, 45]\n",
      "[100, 35]\n",
      "[14, 42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for word in words_dict:\n",
    "    print([len(wiki_wiki[wiki_wiki.word == word][wiki_wiki.gold_sense_id == gold]) for gold in words_dict[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki[\"lem_context\"] = np.nan  # добавили пустой стоблец для лемматизированных контекстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(wiki_wiki.shape[0]): # будем перебирать контексты\n",
    "    lemmatized_list = []\n",
    "    for token in simple_word_tokenize(wiki_wiki['context'][i]):\n",
    "        lemmatized_list.append(morph.parse(token)[0].normal_form)\n",
    "    wiki_wiki[\"lem_context\"][i] = \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki.to_csv(\"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\russe-wsi-kit\\\\preprocessed\\\\wiki_wiki.csv\", \"\\t\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
