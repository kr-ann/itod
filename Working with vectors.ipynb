{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выделение контекстов, нахождение векторов для них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-03 16:38:57,327 : INFO : loading projection weights from <zipfile.ZipExtFile name='model.bin' mode='r' compress_type=deflate>\n",
      "2019-05-03 16:38:57,337 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-03 16:39:07,852 : INFO : loaded (189193, 300) matrix from <zipfile.ZipExtFile [closed]>\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "model_file = \"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\180.zip\"\n",
    "with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "    stream = archive.open('model.bin')\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-03 22:28:24,070 : INFO : loading projection weights from <zipfile.ZipExtFile name='model.bin' mode='r' compress_type=deflate>\n",
      "2019-05-03 22:28:24,071 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-05-03 22:28:37,279 : INFO : loaded (248978, 300) matrix from <zipfile.ZipExtFile [closed]>\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "model_file = \"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\182.zip\"\n",
    "with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "    stream = archive.open('model.bin')\n",
    "    model_skipgram = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"dom\", \"glava\", \"luk\", \"organ\", \"vid\"]\n",
    "path = \"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\RNC_Subcorpus\\\\!raznoje\\\\preprocessed\\\\without_some_POS\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "translit_raznoje = {\"dom\":\"дом\",\n",
    "\"glava\":\"глава\",\n",
    "\"luk\":\"лук\",\n",
    "\"organ\":\"орган\",\n",
    "\"vid\":\"вид\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "\n",
    "def flatten_list(items):\n",
    "    \"\"\"Yield items from any nested iterable; see Reference.\"\"\"\n",
    "    for x in items:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            for sub_x in flatten_list(x):\n",
    "                yield sub_x\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс для контекстов\n",
    "class ContextClass(object):\n",
    "    \n",
    "    def __init__(self, context, sem_set, target_word):\n",
    "        self.context = context\n",
    "        self.sem_set = sem_set\n",
    "        self.target_word = target_word\n",
    "        self.vector = None  # пока что \n",
    "    \n",
    "    def __repr__(self):\n",
    "        list_to_return = [self.sem_set, self.target_word, str(self.context)]\n",
    "        return \" - \".join(list_to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contexts(target_word, windows_size, line):\n",
    "    # line is with POS tags, so is the target word (дом_NOUN)\n",
    "    list_of_contexts = []\n",
    "    \n",
    "    splitted_line = line.split()\n",
    "    for i, word in enumerate(splitted_line):\n",
    "        if word == target_word:\n",
    "            context = []\n",
    "            \n",
    "            # проверка слева\n",
    "            for counter in range(windows_size):\n",
    "                index = i - windows_size + counter\n",
    "                if index < 0:\n",
    "                    # добаляем слева инстансы, которые в последствии дадут пустые вектора\n",
    "                    context.append(\"_#_#_#_\")  # something that is definetely not in the model and will return an empty vector\n",
    "                else:\n",
    "                    context.append(splitted_line[index])\n",
    "            \n",
    "            context.append(splitted_line[i])\n",
    "                           \n",
    "            # теперь проверяем правую сторону\n",
    "            for counter in range(windows_size):\n",
    "                try:\n",
    "                    context.append(splitted_line[i + counter + 1])\n",
    "                except:\n",
    "                    context.append(\"_#_#_#_\")\n",
    "            list_of_contexts.append(context) \n",
    "                \n",
    "    return(list_of_contexts)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем список контекстов\n",
    "\n",
    "contexts_dict = dict()\n",
    "windows_size = 5\n",
    "vector_dimensions = 300\n",
    "\n",
    "for key in translit_raznoje:\n",
    "    # сначала просто список контекстов\n",
    "    contexts_dict[key] = []\n",
    "    target_word = translit_raznoje[key] + \"_NOUN\"\n",
    "    files = os.listdir(path + key + \"\\\\\")\n",
    "    for file in files:\n",
    "        sems = file[4:-4]  # without the \"NEW_\" and \".txt\"\n",
    "        with codecs.open(path + key + \"\\\\\" + file, \"r\", \"utf-8\") as input_file:\n",
    "            lines = input_file.read().split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if len(line.split()) < 3:  # совсем короткие строки нам не нужны\n",
    "                continue\n",
    "            else:\n",
    "                contexts = get_contexts(target_word, windows_size, line)\n",
    "                for context in contexts:\n",
    "                    contexts_dict[key].append(ContextClass(context, sems, target_word))\n",
    "                    \n",
    "with codecs.open(path + \"DICT_contexts.txt\", \"w\", \"utf-8\") as output_dict:\n",
    "    output_dict.write(str(contexts_dict))  # записали, потому что вектора всё равно там не отражаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь можно было бы сделать кэш слов, чтобы не каждый раз заново находились вектора\n",
    "\n",
    "# все контексты в таком виде, что целевое слово посередине, а если слов слева/справа не хватает, там стоит \n",
    "# последовательность \"_#_#_#_\", которая даст пустые вектора (тк её точно нет в модели)\n",
    "\n",
    "def get_context_vector(context, window_size, vector_dimensions, model):\n",
    "    words_vectors = []\n",
    "    context_vector = numpy.zeros(vector_dimensions)\n",
    "    non_zero_vectors_num = 0\n",
    "    \n",
    "    if len(context) != window_size * 2 + 1:\n",
    "        raise ValueError(\"Контекст неправильной размерности\")\n",
    "\n",
    "    for word in context:\n",
    "        if (word in model):\n",
    "            non_zero_vectors_num += 1\n",
    "            words_vectors.append(model[word])\n",
    "        else: \n",
    "            words_vectors.append(numpy.zeros(vector_dimensions))\n",
    "    \n",
    "    if non_zero_vectors_num-1 <= 0:\n",
    "        print(context)\n",
    "    \n",
    "    # fractional decay weighting\n",
    "    for i in range(300):\n",
    "        for j, vector in enumerate(words_vectors):\n",
    "            if j != window_size + 1:\n",
    "                context_vector[i] += vector[i] * ((window_size - math.fabs(window_size + 1 - j))/window_size)\n",
    "                \n",
    "    # + нормализация: после того как получили вектор контекста, делим все его числа на количество непустых векторов:\n",
    "    # так как там идёт суммирование весов для всех слов в контексте, если есть пустые слова, то сумма неоправданно меньше  \n",
    "    # это у нас считал non_zero_vectors_num, но нужно вычесть единицу, так она отвечает за целевое слово\n",
    "    if non_zero_vectors_num <= 1:\n",
    "        return None\n",
    "    else:\n",
    "        for i, digit in enumerate(context_vector):\n",
    "            context_vector[i] = digit/(non_zero_vectors_num-1)\n",
    "        return(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'он_PRON', 'они_PRON', 'дом_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'он_PRON', 'я_PRON', 'дом_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'это_PRON', 'ваш_DET', 'дом_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'стеречь_PROPN', 'наш_DET', 'дом_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'это_PRON', 'он_PRON', 'дом_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', 'гиацинть_PROPN', 'иридодиктиа_NUM', 'ксифиа_NOUN', 'лук_NOUN', 'мускари_NOUN', 'птицемлечникать_NOUN', 'пушкиний_NOUN', 'пролескый_NOUN', 'хионодокс_NOUN']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'коровяк_PROPN', 'котовник_NOUN', 'лук_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', 'ты_PRON', 'лук_NOUN', 'чеснок_ADJ', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'эрот_NOUN', 'натягивающий_VERB', 'лук_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'это_PRON', 'наш_DET', 'орган_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'они_PRON', 'я_PRON', 'вид_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'что_PRON', 'вы_PRON', 'вид_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'а_PROPN', 'какой_DET', 'вид_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'что_PRON', 'я_PRON', 'вид_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', 'что_PRON', 'вы_PRON', 'вид_NOUN', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n",
      "['_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', '_#_#_#_', 'вид_NOUN', 'я_PRON', 'тот_DET', '_#_#_#_', '_#_#_#_', '_#_#_#_']\n"
     ]
    }
   ],
   "source": [
    "# !! выведены контексты, где помимо целевого слова остальных нет в модели\n",
    "\n",
    "# теперь добавляем вектора\n",
    "for key in contexts_dict:\n",
    "    for i, context_instance in enumerate(contexts_dict[key]):\n",
    "        # в первом варианте была просто model \n",
    "        contexts_dict[key][i].vector = get_context_vector(context_instance.context, windows_size, vector_dimensions, model_skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "3629\n",
      "glava\n",
      "733\n",
      "luk\n",
      "2642\n",
      "organ\n",
      "1136\n",
      "vid\n",
      "3033\n"
     ]
    }
   ],
   "source": [
    "for key in contexts_dict:\n",
    "    print(key)\n",
    "    print(len(contexts_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем из словаря такие контексты\n",
    "for key in contexts_dict:\n",
    "    for i, context_instance in enumerate(contexts_dict[key]):\n",
    "        if context_instance.vector is None:\n",
    "            contexts_dict[key].pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "3624\n",
      "glava\n",
      "733\n",
      "luk\n",
      "2638\n",
      "organ\n",
      "1135\n",
      "vid\n",
      "3027\n"
     ]
    }
   ],
   "source": [
    "for key in contexts_dict:\n",
    "    print(key)\n",
    "    print(len(contexts_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# примерчик\n",
    "sample_context = [\"ребенок_NOUN\", \"страдать_VERB\", \"врожденный_ADJ\", \"порок_NOUN\", \"различный_ADJ\", \n",
    "                  \"орган_NOUN\", \n",
    "                  \"новообразование_NOUN\", \"другой_ADJ\", \"тяжелый_ADJ\", \"недуг_NOUN\", \"можно_ADV\"]\n",
    "res = get_context_vector(sample_context, 5, 300, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "В словаре contexts_dict по ключам-названиям слов находятся инстансы класса ContextClass, у которых\n",
    "        self.context - словарь длиной 11, где шестое слово - целевое, а вокруг другие слова\n",
    "        self.sem_set - название файла, из которого он взят\n",
    "        self.target_word - целевое слово в формате \"слово_NOUN\"\n",
    "        self.vector - вектор, посчитанный для контекста"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Кластеризуем вектора (количество кластеров - сколько у нас значений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "8\n",
      "glava\n",
      "4\n",
      "luk\n",
      "2\n",
      "organ\n",
      "4\n",
      "vid\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# словарь, значение которого для каждого целевого слова - зип файл с парами (сема, присвоенный номер кластера) \n",
    "dict_with_cluster_sem_correspondence = dict()\n",
    "\n",
    "for key in contexts_dict:\n",
    "    files = os.listdir(path + key + \"\\\\\")\n",
    "    NUM_CLUSTERS = len(files)\n",
    "    print(key)\n",
    "    print(NUM_CLUSTERS)\n",
    "    list_with_vectors = [instance.vector for instance in contexts_dict[key]]  # все векторы\n",
    "    list_with_sems = [instance.sem_set for instance in contexts_dict[key]]  # все семы\n",
    "    kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "    list_with_cluster_labels = kclusterer.cluster(list_with_vectors, assign_clusters=True)\n",
    "    dict_with_cluster_sem_correspondence[key] = zip(list_with_sems, list_with_cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_with_cluster_sem_correspondence:\n",
    "    dict_with_cluster_sem_correspondence[key] = list(dict_with_cluster_sem_correspondence[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 6), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 4), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 4), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 5)]\n",
      "[(\"{'r-concr_der-shift_dt-partb'}\", 3), (\"{'r-concr_der-shift_dt-partb'}\", 2), (\"{'r-concr_der-shift_dt-partb'}\", 2), (\"{'r-concr_der-shift_dt-partb'}\", 3), (\"{'r-concr_der-shift_dt-partb'}\", 2), (\"{'r-concr_der-shift_dt-partb'}\", 1), (\"{'r-concr_der-shift_dt-partb'}\", 1), (\"{'r-concr_der-shift_dt-partb'}\", 3), (\"{'r-concr_der-shift_dt-partb'}\", 2), (\"{'r-concr_der-shift_dt-partb'}\", 1)]\n",
      "[(\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1), (\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1)]\n",
      "[(\"{'r-concr_der-shift_dt-partb'}\", 1), (\"{'r-concr_der-shift_dt-partb'}\", 3), (\"{'r-concr_der-shift_dt-partb'}\", 0), (\"{'r-concr_der-shift_dt-partb'}\", 0), (\"{'r-concr_der-shift_dt-partb'}\", 0), (\"{'r-concr_der-shift_dt-partb'}\", 1), (\"{'r-concr_der-shift_dt-partb'}\", 0), (\"{'r-concr_der-shift_dt-partb'}\", 1), (\"{'r-concr_der-shift_dt-partb'}\", 1), (\"{'r-concr_der-shift_dt-partb'}\", 1)]\n",
      "[(\"{'r-abstr_der-shift'}\", 1), (\"{'r-abstr_der-shift'}\", 5), (\"{'r-abstr_der-shift'}\", 1), (\"{'r-abstr_der-shift'}\", 1), (\"{'r-abstr_der-shift'}\", 1), (\"{'r-abstr_der-shift'}\", 3), (\"{'r-abstr_der-shift'}\", 1), (\"{'r-abstr_der-shift'}\", 5), (\"{'r-abstr_der-shift'}\", 0), (\"{'r-abstr_der-shift'}\", 1)]\n"
     ]
    }
   ],
   "source": [
    "for key in dict_with_cluster_sem_correspondence:\n",
    "    print(dict_with_cluster_sem_correspondence[key][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "3629\n",
      "glava\n",
      "733\n",
      "luk\n",
      "2642\n",
      "organ\n",
      "1136\n",
      "vid\n",
      "3033\n"
     ]
    }
   ],
   "source": [
    "for key in dict_with_cluster_sem_correspondence:\n",
    "    print(key)\n",
    "    print(len(dict_with_cluster_sem_correspondence[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "2\n",
      "glava\n",
      "2\n",
      "luk\n",
      "2\n",
      "organ\n",
      "2\n",
      "vid\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# смотрим, что в рандомном - пятом - элементе два значения: это list_with_sems, list_with_cluster_labels\n",
    "for key in dict_with_cluster_sem_correspondence:\n",
    "    print(key)\n",
    "    print(len(dict_with_cluster_sem_correspondence[key][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "Всего правильных контекстов\n",
      "[(\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\", 269), (\"{'r-concr_t-constr_top-contain',_'r-concr_t-space'}\", 999), (\"{'r-concr_t-constr_top-contain'}\", 2104), (\"{'r-concr_t-group_pt-set_sc-hum',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\", 46), (\"{'r-concr_t-group_pt-set_sc-hum'}\", 23), (\"{'r-concr_t-org',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\", 71), (\"{'r-concr_t-org'}\", 13), (\"{'r-concr_t-space'}\", 99)]\n",
      "glava\n",
      "Всего правильных контекстов\n",
      "[(\"{'r-concr_der-shift_dt-partb'}\", 139), (\"{'r-concr_pt-partb_pc-hum'}\", 8), (\"{'r-concr_t-hum'}\", 311), (\"{'r-concr_t-text_pt-part_pc-text'}\", 275)]\n",
      "luk\n",
      "Всего правильных контекстов\n",
      "[(\"{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\", 1976), (\"{'r-concr_t-tool-weapon_top-arc'}\", 662)]\n",
      "organ\n",
      "Всего правильных контекстов\n",
      "[(\"{'r-concr_der-shift_dt-partb'}\", 12), (\"{'r-concr_pt-partb_pc-hum_pc-animal_hi-class'}\", 170), (\"{'r-concr_t-org_hi-class'}\", 923), (\"{'r-concr_t-tool-mus'}\", 30)]\n",
      "vid\n",
      "Всего правильных контекстов\n",
      "[(\"{'r-abstr_der-shift'}\", 1150), (\"{'r-abstr_r-concr_pt-set_sc-X'}\", 656), (\"{'r-abstr_t-ment'}\", 13), (\"{'r-abstr_t-perc_der-v'}\", 1191), (\"{'r-concr_t-doc'}\", 7), (\"{'r-concr_t-workart'}\", 10)]\n"
     ]
    }
   ],
   "source": [
    "# смотрим, сколько в исходных файлых контекстов на каждое значение\n",
    "for key in dict_with_cluster_sem_correspondence:\n",
    "    files = os.listdir(path + key + \"\\\\\")\n",
    "    senses = []\n",
    "    for file in files:\n",
    "        senses.append(file[4:-4])\n",
    "    \n",
    "    num_true_contexts = [0]*len(senses)\n",
    "    for i, sense in enumerate(senses):\n",
    "        for pair in dict_with_cluster_sem_correspondence[key]:\n",
    "            if pair[0] == sense:\n",
    "                num_true_contexts[i] += 1\n",
    "    print(key)\n",
    "    print(\"Всего правильных контекстов\")\n",
    "    print(list(zip(senses, num_true_contexts)))\n",
    "        \n",
    "    \n",
    "    #print(list(dict_with_cluster_sem_correspondence[key])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новый словарь - значения - тоже словари, где ключами в свою очередь являются различные смыслы целевого слова, а "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-org'} 269\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-space'} 999\n",
      "{'r-concr_t-constr_top-contain'} 2104\n",
      "{'r-concr_t-group_pt-set_sc-hum',_'r-concr_t-constr_top-contain',_'r-concr_t-space'} 46\n",
      "{'r-concr_t-group_pt-set_sc-hum'} 23\n",
      "{'r-concr_t-org',_'r-concr_t-constr_top-contain',_'r-concr_t-space'} 71\n",
      "{'r-concr_t-org'} 13\n",
      "{'r-concr_t-space'} 99\n",
      "glava\n",
      "{'r-concr_der-shift_dt-partb'} 139\n",
      "{'r-concr_pt-partb_pc-hum'} 8\n",
      "{'r-concr_t-hum'} 311\n",
      "{'r-concr_t-text_pt-part_pc-text'} 275\n",
      "luk\n",
      "{'r-concr_t-plant_t-fruit_t-food_pt-aggr'} 1976\n",
      "{'r-concr_t-tool-weapon_top-arc'} 662\n",
      "organ\n",
      "{'r-concr_der-shift_dt-partb'} 12\n",
      "{'r-concr_pt-partb_pc-hum_pc-animal_hi-class'} 170\n",
      "{'r-concr_t-org_hi-class'} 923\n",
      "{'r-concr_t-tool-mus'} 30\n",
      "vid\n",
      "{'r-abstr_der-shift'} 1150\n",
      "{'r-abstr_r-concr_pt-set_sc-X'} 656\n",
      "{'r-abstr_t-ment'} 13\n",
      "{'r-abstr_t-perc_der-v'} 1191\n",
      "{'r-concr_t-doc'} 7\n",
      "{'r-concr_t-workart'} 10\n"
     ]
    }
   ],
   "source": [
    "new_dict_with_all_assigned_clusters = dict()\n",
    "\n",
    "for key in dict_with_cluster_sem_correspondence:\n",
    "    new_dict_with_all_assigned_clusters[key] = dict()\n",
    "    for pair in dict_with_cluster_sem_correspondence[key]:\n",
    "        new_dict_with_all_assigned_clusters[key].setdefault(pair[0], [])\n",
    "        new_dict_with_all_assigned_clusters[key][pair[0]].append(pair[1])\n",
    "\n",
    "# посмотрели, что здесь всего столько же контекстов получается - уже хорошо\n",
    "for key in new_dict_with_all_assigned_clusters:\n",
    "    print(key)\n",
    "    for sema in new_dict_with_all_assigned_clusters[key]:\n",
    "        print(sema, len(new_dict_with_all_assigned_clusters[key][sema]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\n",
      "[1, 1, 2, 2, 2, 1, 2, 6, 1, 3]\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-space'}\n",
      "[4, 1, 3, 3, 7, 7, 3, 0, 5, 5]\n",
      "{'r-concr_t-constr_top-contain'}\n",
      "[6, 6, 6, 6, 0, 6, 6, 7, 2, 5]\n",
      "{'r-concr_t-group_pt-set_sc-hum',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\n",
      "[0, 4, 0, 0, 1, 0, 7, 3, 0, 4]\n",
      "{'r-concr_t-group_pt-set_sc-hum'}\n",
      "[7, 0, 7, 7, 7, 1, 7, 0, 4, 7]\n",
      "{'r-concr_t-org',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\n",
      "[4, 2, 7, 0, 4, 0, 0, 6, 7, 1]\n",
      "{'r-concr_t-org'}\n",
      "[2, 2, 2, 2, 1, 2, 1, 2, 1, 1]\n",
      "{'r-concr_t-space'}\n",
      "[3, 0, 0, 5, 4, 7, 3, 4, 4, 4]\n",
      "glava\n",
      "{'r-concr_der-shift_dt-partb'}\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 0, 2]\n",
      "{'r-concr_pt-partb_pc-hum'}\n",
      "[2, 3, 3, 3, 3, 2, 2, 3]\n",
      "{'r-concr_t-hum'}\n",
      "[3, 2, 2, 0, 1, 2, 1, 0, 1, 2]\n",
      "{'r-concr_t-text_pt-part_pc-text'}\n",
      "[2, 2, 2, 2, 0, 0, 0, 0, 0, 3]\n",
      "luk\n",
      "{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\n",
      "[0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "{'r-concr_t-tool-weapon_top-arc'}\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "organ\n",
      "{'r-concr_der-shift_dt-partb'}\n",
      "[0, 1, 2, 3, 3, 3, 3, 3, 3, 3]\n",
      "{'r-concr_pt-partb_pc-hum_pc-animal_hi-class'}\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "{'r-concr_t-org_hi-class'}\n",
      "[3, 2, 0, 3, 3, 0, 0, 1, 0, 0]\n",
      "{'r-concr_t-tool-mus'}\n",
      "[3, 3, 3, 3, 3, 0, 3, 3, 3, 3]\n",
      "vid\n",
      "{'r-abstr_der-shift'}\n",
      "[0, 1, 0, 0, 1, 1, 0, 1, 5, 0]\n",
      "{'r-abstr_r-concr_pt-set_sc-X'}\n",
      "[1, 1, 1, 0, 0, 0, 1, 5, 1, 0]\n",
      "{'r-abstr_t-ment'}\n",
      "[0, 5, 5, 2, 1, 1, 1, 1, 2, 1]\n",
      "{'r-abstr_t-perc_der-v'}\n",
      "[0, 1, 2, 2, 5, 2, 5, 3, 4, 4]\n",
      "{'r-concr_t-doc'}\n",
      "[1, 0, 0, 2, 1, 4, 4]\n",
      "{'r-concr_t-workart'}\n",
      "[4, 1, 4, 4, 4, 4, 4, 1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# смотрим для каждого значения - к каким кластерам отнесены его контексты (первые 10)\n",
    "for key in new_dict_with_all_assigned_clusters:\n",
    "    print(key)\n",
    "    for sema in new_dict_with_all_assigned_clusters[key]:\n",
    "        print(sema)\n",
    "        print(new_dict_with_all_assigned_clusters[key][sema][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\n",
      "1 59\n",
      "2 59\n",
      "6 19\n",
      "3 37\n",
      "7 44\n",
      "4 20\n",
      "5 11\n",
      "0 20\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-space'}\n",
      "4 183\n",
      "1 44\n",
      "3 265\n",
      "7 215\n",
      "0 194\n",
      "5 61\n",
      "6 13\n",
      "2 24\n",
      "{'r-concr_t-constr_top-contain'}\n",
      "6 325\n",
      "0 197\n",
      "7 313\n",
      "2 64\n",
      "5 366\n",
      "3 407\n",
      "4 256\n",
      "1 176\n",
      "{'r-concr_t-group_pt-set_sc-hum',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\n",
      "0 13\n",
      "4 2\n",
      "1 2\n",
      "7 13\n",
      "3 11\n",
      "2 1\n",
      "5 3\n",
      "6 1\n",
      "{'r-concr_t-group_pt-set_sc-hum'}\n",
      "7 10\n",
      "0 5\n",
      "1 1\n",
      "4 4\n",
      "6 2\n",
      "3 1\n",
      "{'r-concr_t-org',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\n",
      "4 9\n",
      "2 6\n",
      "7 13\n",
      "0 10\n",
      "6 10\n",
      "1 7\n",
      "3 11\n",
      "5 5\n",
      "{'r-concr_t-org'}\n",
      "2 6\n",
      "1 5\n",
      "0 1\n",
      "5 1\n",
      "{'r-concr_t-space'}\n",
      "3 34\n",
      "0 25\n",
      "5 2\n",
      "4 15\n",
      "7 14\n",
      "2 6\n",
      "1 3\n",
      "glava\n",
      "{'r-concr_der-shift_dt-partb'}\n",
      "2 71\n",
      "0 20\n",
      "3 13\n",
      "1 35\n",
      "{'r-concr_pt-partb_pc-hum'}\n",
      "2 3\n",
      "3 5\n",
      "{'r-concr_t-hum'}\n",
      "3 35\n",
      "2 72\n",
      "0 94\n",
      "1 110\n",
      "{'r-concr_t-text_pt-part_pc-text'}\n",
      "2 129\n",
      "0 45\n",
      "3 87\n",
      "1 14\n",
      "luk\n",
      "{'r-concr_t-plant_t-fruit_t-food_pt-aggr'}\n",
      "0 620\n",
      "1 1356\n",
      "{'r-concr_t-tool-weapon_top-arc'}\n",
      "0 661\n",
      "1 1\n",
      "organ\n",
      "{'r-concr_der-shift_dt-partb'}\n",
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "3 9\n",
      "{'r-concr_pt-partb_pc-hum_pc-animal_hi-class'}\n",
      "3 135\n",
      "0 29\n",
      "2 6\n",
      "{'r-concr_t-org_hi-class'}\n",
      "3 124\n",
      "2 343\n",
      "0 206\n",
      "1 250\n",
      "{'r-concr_t-tool-mus'}\n",
      "3 23\n",
      "0 5\n",
      "2 2\n",
      "vid\n",
      "{'r-abstr_der-shift'}\n",
      "0 195\n",
      "1 313\n",
      "5 238\n",
      "2 119\n",
      "4 138\n",
      "3 147\n",
      "{'r-abstr_r-concr_pt-set_sc-X'}\n",
      "1 167\n",
      "0 229\n",
      "5 103\n",
      "3 81\n",
      "2 30\n",
      "4 46\n",
      "{'r-abstr_t-ment'}\n",
      "0 1\n",
      "5 4\n",
      "2 2\n",
      "1 6\n",
      "{'r-abstr_t-perc_der-v'}\n",
      "0 19\n",
      "1 116\n",
      "2 465\n",
      "5 220\n",
      "3 20\n",
      "4 351\n",
      "{'r-concr_t-doc'}\n",
      "1 2\n",
      "0 2\n",
      "2 1\n",
      "4 2\n",
      "{'r-concr_t-workart'}\n",
      "4 7\n",
      "1 2\n",
      "3 1\n"
     ]
    }
   ],
   "source": [
    "for key in new_dict_with_all_assigned_clusters:\n",
    "    print(key)\n",
    "    for sema in new_dict_with_all_assigned_clusters[key]:\n",
    "        print(sema)\n",
    "        small_dict = dict()\n",
    "        for number in new_dict_with_all_assigned_clusters[key][sema]:\n",
    "            small_dict.setdefault(number, 0)\n",
    "            small_dict[number] += 1\n",
    "        for element in small_dict:\n",
    "            print(element, small_dict[element])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подобие классификации"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) Для каждого значения по размеченному корпусу находим средний вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_mean_vectors = []\n",
    "for sem in dict_for_dom:\n",
    "    array = np.array(dict_for_dom[sem])\n",
    "    mean = np.mean(array,axis=0)\n",
    "    \n",
    "    dom_mean_vectors.append([sem, mean.tolist()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "glava_mean_vectors = []\n",
    "for sem in dict_for_glava:\n",
    "    array = np.array(dict_for_glava[sem])\n",
    "    mean = np.mean(array,axis=0)\n",
    "    \n",
    "    glava_mean_vectors.append([sem, mean.tolist()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "luk_mean_vectors = []\n",
    "for sem in dict_for_luk:\n",
    "    array = np.array(dict_for_luk[sem])\n",
    "    mean = np.mean(array,axis=0)\n",
    "    \n",
    "    luk_mean_vectors.append([sem, mean.tolist()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_mean_vectors = []\n",
    "for sem in dict_for_organ:\n",
    "    array = np.array(dict_for_organ[sem])\n",
    "    mean = np.mean(array,axis=0)\n",
    "    \n",
    "    organ_mean_vectors.append([sem, mean.tolist()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_mean_vectors = []\n",
    "for sem in dict_for_vid:\n",
    "    array = np.array(dict_for_vid[sem])\n",
    "    mean = np.mean(array,axis=0)\n",
    "    \n",
    "    vid_mean_vectors.append([sem, mean.tolist()])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2) В скрипте предобработки обработали \"плохие\" контексты: лемматизировали, добавили ЧР-теги UDPipe, удалили функциональные слова. Здесь строим инстансы контекстов и вычисляем для них вектора (если достаточное количество непустых слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "translit = {\"dom\":\"Дом\",\n",
    "\"glava\":\"Глава\",\n",
    "\"luk\":\"Лук\",\n",
    "\"organ\":\"Орган\",\n",
    "\"vid\":\"Вид\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\RNC_Subcorpus\\\\!raznoje\\\\raw_texts\\\\without_punctuation\\\\lemmatized_bad\\\\without_some_POS\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отдельно плохие контексты для каждого слова (для 'дома' нет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_dict = dict()\n",
    "windows_size = 5\n",
    "vector_dimensions = 300\n",
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "for key in translit:\n",
    "    # сначала просто список контекстов\n",
    "    contexts_dict[key] = []\n",
    "    target_word = translit_raznoje[key] + \"_NOUN\"\n",
    "    for file in files:\n",
    "        if key in file:\n",
    "            with codecs.open(path + file, \"r\", \"utf-8\") as input_file:\n",
    "                lines = input_file.read().split(\"\\n\")\n",
    "            for line in lines:\n",
    "                if len(line.split()) < 3:  # совсем короткие строки нам не нужны\n",
    "                    continue\n",
    "                else:\n",
    "                    contexts = get_contexts(target_word, windows_size, line)\n",
    "                    for context in contexts:\n",
    "                        contexts_dict[key].append(ContextClass(context, sems, target_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom 0\n",
      "glava 44\n",
      "luk 83\n",
      "organ 9\n",
      "vid 176\n"
     ]
    }
   ],
   "source": [
    "for key in contexts_dict:\n",
    "    print(key, len(contexts_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем вектора\n",
    "for key in contexts_dict:\n",
    "    for i, context_instance in enumerate(contexts_dict[key]):\n",
    "        # в первом варианте была просто model \n",
    "        contexts_dict[key][i].vector = get_context_vector(context_instance.context, windows_size, vector_dimensions, model_skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom 0\n",
      "glava 44\n",
      "luk 83\n",
      "organ 9\n",
      "vid 176\n"
     ]
    }
   ],
   "source": [
    "for key in contexts_dict:\n",
    "    print(key, len(contexts_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем из словаря контексты, где все слова в окне получили нулевой вектор (видимо, таких нет)\n",
    "for key in contexts_dict:\n",
    "    for i, context_instance in enumerate(contexts_dict[key]):\n",
    "        if context_instance.vector is None:\n",
    "            contexts_dict[key].pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dom 0\n",
      "glava 44\n",
      "luk 83\n",
      "organ 9\n",
      "vid 176\n"
     ]
    }
   ],
   "source": [
    "for key in contexts_dict:\n",
    "    print(key, len(contexts_dict[key]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 3) Для каждого вектора плохих контекстов находим самый близкий к нему по косинусному расстоянию вектор значений и записываем в файл присвоенное значение и контекст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_with_mean_vectors['dom'] = dom_mean_vectors # словарь, пары [сема, вектор]\n",
    "dict_with_mean_vectors['glava'] = glava_mean_vectors\n",
    "dict_with_mean_vectors['luk'] = luk_mean_vectors\n",
    "dict_with_mean_vectors['organ'] = organ_mean_vectors\n",
    "dict_with_mean_vectors['vid'] = vid_mean_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\boss\\\\Documents\\\\Diploma\\\\RNC_Subcorpus\\\\!raznoje\\\\raw_texts\\\\without_punctuation\\\\lemmatized_bad\\\\\"\n",
    "\n",
    "for key in contexts_dict:\n",
    "    for instance in contexts_dict[key]:\n",
    "        vector = np.array(instance.vector).reshape(1,300)\n",
    "        cosine_values = []\n",
    "        for pair in dict_with_mean_vectors[key]:\n",
    "            sem_vector = np.array(pair[1]).reshape(1,300)\n",
    "            cosine_values.append(cos(vector,sem_vector).tolist())\n",
    "\n",
    "        cosine_values = list(flatten_list(cosine_values))\n",
    "        index_max_cosine = cosine_values.index(max(cosine_values))\n",
    "        the_sem = dict_with_mean_vectors[key][index_max_cosine][0]\n",
    "        \n",
    "        # это мы просто записали сему, к которой отнесён контекст, и сам контекст - но в неудобном виде\n",
    "        # with codecs.open(path+\"attributed_contexts_for_\" + key + \".txt\", \"a\", \"utf-8\") as output:\n",
    "            # output.write(the_sem + \" \" + str(instance.context) + \"\\n\")\n",
    "        if key != 'organ':\n",
    "            with codecs.open(path+\"readable_contexts_for_\" + key + \".txt\", \"a\", \"utf-8\") as output:\n",
    "                output.write(the_sem + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM классификация "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Still effective in cases where number of dimensions is greater than the number of samples. However, if the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context_Class entity in contexts_dict: context, sem_set, target_word, vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для значений дома "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# значений - 8\n",
    "\n",
    "# словарь, в котором ключи - встречающиеся семы, значение - лист с векторами\n",
    "dict_for_dom = dict()\n",
    "for entity in contexts_dict[\"dom\"]:\n",
    "    dict_for_dom.setdefault(entity.sem_set, [])\n",
    "    dict_for_dom[entity.sem_set].append(entity.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r-concr_t-constr_top-contain',_'r-concr_t-org'} 269\n",
      "{'r-concr_t-constr_top-contain',_'r-concr_t-space'} 999\n",
      "{'r-concr_t-constr_top-contain'} 2104\n",
      "{'r-concr_t-group_pt-set_sc-hum',_'r-concr_t-constr_top-contain',_'r-concr_t-space'} 46\n",
      "{'r-concr_t-group_pt-set_sc-hum'} 23\n",
      "{'r-concr_t-org',_'r-concr_t-constr_top-contain',_'r-concr_t-space'} 71\n",
      "{'r-concr_t-org'} 13\n",
      "{'r-concr_t-space'} 99\n"
     ]
    }
   ],
   "source": [
    "for key in dict_for_dom:\n",
    "    print(key, len(dict_for_dom[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала для первой семы: {'r-concr_t-constr_top-contain',_'r-concr_t-org'}\n",
    "dfr_positive = pd.DataFrame(dict_for_dom[\"{'r-concr_t-constr_top-contain',_'r-concr_t-org'}\"])\n",
    "dfr_negative = pd.DataFrame(dict_for_dom[\"{'r-concr_t-constr_top-contain',_'r-concr_t-space'}\"] + \n",
    "                            dict_for_dom[\"{'r-concr_t-constr_top-contain'}\"] + \n",
    "                            dict_for_dom[\"{'r-concr_t-group_pt-set_sc-hum',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\"] + \n",
    "                            dict_for_dom[\"{'r-concr_t-group_pt-set_sc-hum'}\"] +\n",
    "                            dict_for_dom[\"{'r-concr_t-org',_'r-concr_t-constr_top-contain',_'r-concr_t-space'}\"] +\n",
    "                            dict_for_dom[\"{'r-concr_t-org'}\"] + \n",
    "                            dict_for_dom[\"{'r-concr_t-space'}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3355, 300)\n",
      "(269, 300)\n"
     ]
    }
   ],
   "source": [
    "print(dfr_negative.shape)\n",
    "print(dfr_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.112655 -0.015101  0.062594 -0.082058  0.003030  0.083630 -0.039967   \n",
      "1  0.015530 -0.070638  0.066764 -0.055343  0.004817  0.090311  0.000892   \n",
      "2  0.083353 -0.007032  0.137873 -0.121726  0.017375  0.097917 -0.117281   \n",
      "3 -0.040353 -0.066811  0.122380 -0.017725 -0.030651  0.074216 -0.076020   \n",
      "4 -0.056214  0.024573  0.018005 -0.027554 -0.025000  0.056884 -0.015050   \n",
      "\n",
      "        7         8         9      ...          290       291       292  \\\n",
      "0  0.046675  0.007770 -0.131968    ...     0.016537  0.042334 -0.088649   \n",
      "1  0.036203 -0.027513 -0.091848    ...     0.012817  0.057783 -0.055656   \n",
      "2  0.076937  0.090479 -0.074229    ...     0.032286  0.092625 -0.019842   \n",
      "3  0.072242  0.004307 -0.112502    ...     0.042509 -0.039092 -0.045481   \n",
      "4  0.039105 -0.015092 -0.026991    ...    -0.002306  0.047317 -0.026562   \n",
      "\n",
      "        293       294       295       296       297       298       299  \n",
      "0  0.122610  0.064857  0.036174  0.023200 -0.016464  0.155182  0.124007  \n",
      "1  0.001092  0.080691 -0.014756 -0.022548  0.081506  0.142143  0.117946  \n",
      "2  0.101258  0.026017  0.045355  0.042640 -0.094668  0.178436  0.130513  \n",
      "3  0.106486  0.108514 -0.058858 -0.029696 -0.096235  0.077846  0.132690  \n",
      "4  0.038275  0.045017  0.025227  0.025171 -0.022316  0.025044  0.054880  \n",
      "\n",
      "[5 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfr_negative.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим столбец с целевой переменной\n",
    "dfr_positive['class'] = pd.Series(np.ones(dfr_positive.shape[0], dtype=int), index=dfr_positive.index)\n",
    "dfr_negative['class'] = pd.Series(np.zeros(dfr_negative.shape[0], dtype=int), index=dfr_negative.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112655</td>\n",
       "      <td>-0.015101</td>\n",
       "      <td>0.062594</td>\n",
       "      <td>-0.082058</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.083630</td>\n",
       "      <td>-0.039967</td>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>-0.131968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042334</td>\n",
       "      <td>-0.088649</td>\n",
       "      <td>0.122610</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.036174</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>-0.016464</td>\n",
       "      <td>0.155182</td>\n",
       "      <td>0.124007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015530</td>\n",
       "      <td>-0.070638</td>\n",
       "      <td>0.066764</td>\n",
       "      <td>-0.055343</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.090311</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.036203</td>\n",
       "      <td>-0.027513</td>\n",
       "      <td>-0.091848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057783</td>\n",
       "      <td>-0.055656</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.080691</td>\n",
       "      <td>-0.014756</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>0.081506</td>\n",
       "      <td>0.142143</td>\n",
       "      <td>0.117946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083353</td>\n",
       "      <td>-0.007032</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>-0.121726</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>-0.117281</td>\n",
       "      <td>0.076937</td>\n",
       "      <td>0.090479</td>\n",
       "      <td>-0.074229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092625</td>\n",
       "      <td>-0.019842</td>\n",
       "      <td>0.101258</td>\n",
       "      <td>0.026017</td>\n",
       "      <td>0.045355</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>-0.094668</td>\n",
       "      <td>0.178436</td>\n",
       "      <td>0.130513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.040353</td>\n",
       "      <td>-0.066811</td>\n",
       "      <td>0.122380</td>\n",
       "      <td>-0.017725</td>\n",
       "      <td>-0.030651</td>\n",
       "      <td>0.074216</td>\n",
       "      <td>-0.076020</td>\n",
       "      <td>0.072242</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>-0.112502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039092</td>\n",
       "      <td>-0.045481</td>\n",
       "      <td>0.106486</td>\n",
       "      <td>0.108514</td>\n",
       "      <td>-0.058858</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>-0.096235</td>\n",
       "      <td>0.077846</td>\n",
       "      <td>0.132690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056214</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>-0.027554</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.039105</td>\n",
       "      <td>-0.015092</td>\n",
       "      <td>-0.026991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047317</td>\n",
       "      <td>-0.026562</td>\n",
       "      <td>0.038275</td>\n",
       "      <td>0.045017</td>\n",
       "      <td>0.025227</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>-0.022316</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.054880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.112655 -0.015101  0.062594 -0.082058  0.003030  0.083630 -0.039967   \n",
       "1  0.015530 -0.070638  0.066764 -0.055343  0.004817  0.090311  0.000892   \n",
       "2  0.083353 -0.007032  0.137873 -0.121726  0.017375  0.097917 -0.117281   \n",
       "3 -0.040353 -0.066811  0.122380 -0.017725 -0.030651  0.074216 -0.076020   \n",
       "4 -0.056214  0.024573  0.018005 -0.027554 -0.025000  0.056884 -0.015050   \n",
       "\n",
       "          7         8         9  ...         291       292       293  \\\n",
       "0  0.046675  0.007770 -0.131968  ...    0.042334 -0.088649  0.122610   \n",
       "1  0.036203 -0.027513 -0.091848  ...    0.057783 -0.055656  0.001092   \n",
       "2  0.076937  0.090479 -0.074229  ...    0.092625 -0.019842  0.101258   \n",
       "3  0.072242  0.004307 -0.112502  ...   -0.039092 -0.045481  0.106486   \n",
       "4  0.039105 -0.015092 -0.026991  ...    0.047317 -0.026562  0.038275   \n",
       "\n",
       "        294       295       296       297       298       299  class  \n",
       "0  0.064857  0.036174  0.023200 -0.016464  0.155182  0.124007      0  \n",
       "1  0.080691 -0.014756 -0.022548  0.081506  0.142143  0.117946      0  \n",
       "2  0.026017  0.045355  0.042640 -0.094668  0.178436  0.130513      0  \n",
       "3  0.108514 -0.058858 -0.029696 -0.096235  0.077846  0.132690      0  \n",
       "4  0.045017  0.025227  0.025171 -0.022316  0.025044  0.054880      0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [dfr_negative, dfr_positive]\n",
    "all_data = pd.concat(frames)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3624, 301)\n"
     ]
    }
   ],
   "source": [
    "data_shuffled = shuffle(all_data, random_state=11)\n",
    "print(data_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_shuffled[data_shuffled.columns[:-1]]\n",
    "y = data_shuffled['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>-0.057357</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.190454</td>\n",
       "      <td>-0.035989</td>\n",
       "      <td>-0.028563</td>\n",
       "      <td>0.046286</td>\n",
       "      <td>-0.040437</td>\n",
       "      <td>-0.039086</td>\n",
       "      <td>-0.028037</td>\n",
       "      <td>-0.133084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071813</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>-0.038081</td>\n",
       "      <td>0.141563</td>\n",
       "      <td>-0.057276</td>\n",
       "      <td>0.042845</td>\n",
       "      <td>-0.014302</td>\n",
       "      <td>-0.093607</td>\n",
       "      <td>0.137064</td>\n",
       "      <td>0.166098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>-0.078542</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.061703</td>\n",
       "      <td>-0.036626</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.029976</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.045481</td>\n",
       "      <td>-0.045661</td>\n",
       "      <td>-0.008023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025971</td>\n",
       "      <td>0.095802</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>0.072536</td>\n",
       "      <td>0.022610</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>-0.056011</td>\n",
       "      <td>0.031867</td>\n",
       "      <td>0.119171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>-0.078240</td>\n",
       "      <td>0.026426</td>\n",
       "      <td>0.158875</td>\n",
       "      <td>-0.096029</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.058469</td>\n",
       "      <td>-0.021011</td>\n",
       "      <td>0.083042</td>\n",
       "      <td>-0.079625</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014439</td>\n",
       "      <td>0.122838</td>\n",
       "      <td>-0.075680</td>\n",
       "      <td>0.154673</td>\n",
       "      <td>0.173832</td>\n",
       "      <td>0.036977</td>\n",
       "      <td>-0.079820</td>\n",
       "      <td>0.016101</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>0.113778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>-0.046505</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.053857</td>\n",
       "      <td>-0.034735</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>-0.032970</td>\n",
       "      <td>-0.112619</td>\n",
       "      <td>-0.046146</td>\n",
       "      <td>-0.111943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047041</td>\n",
       "      <td>0.159223</td>\n",
       "      <td>-0.004111</td>\n",
       "      <td>0.091835</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>0.031678</td>\n",
       "      <td>-0.031677</td>\n",
       "      <td>-0.049278</td>\n",
       "      <td>0.137576</td>\n",
       "      <td>0.009447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>-0.071837</td>\n",
       "      <td>-0.027748</td>\n",
       "      <td>0.036022</td>\n",
       "      <td>-0.017426</td>\n",
       "      <td>-0.031876</td>\n",
       "      <td>0.038657</td>\n",
       "      <td>-0.051708</td>\n",
       "      <td>0.033583</td>\n",
       "      <td>-0.040096</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.061388</td>\n",
       "      <td>-0.035305</td>\n",
       "      <td>0.052678</td>\n",
       "      <td>0.030727</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>-0.065728</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.109456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "530  -0.057357 -0.006248  0.190454 -0.035989 -0.028563  0.046286 -0.040437   \n",
       "3203 -0.078542  0.024660  0.061703 -0.036626  0.021298  0.029976 -0.014374   \n",
       "2207 -0.078240  0.026426  0.158875 -0.096029  0.004387  0.058469 -0.021011   \n",
       "2278 -0.046505  0.068337  0.053857 -0.034735 -0.000132  0.012133 -0.032970   \n",
       "3052 -0.071837 -0.027748  0.036022 -0.017426 -0.031876  0.038657 -0.051708   \n",
       "\n",
       "           7         8         9      ...          290       291       292  \\\n",
       "530  -0.039086 -0.028037 -0.133084    ...     0.071813  0.092946 -0.038081   \n",
       "3203 -0.045481 -0.045661 -0.008023    ...    -0.025971  0.095802 -0.028340   \n",
       "2207  0.083042 -0.079625 -0.001572    ...    -0.014439  0.122838 -0.075680   \n",
       "2278 -0.112619 -0.046146 -0.111943    ...    -0.047041  0.159223 -0.004111   \n",
       "3052  0.033583 -0.040096  0.020691    ...     0.003473  0.061388 -0.035305   \n",
       "\n",
       "           293       294       295       296       297       298       299  \n",
       "530   0.141563 -0.057276  0.042845 -0.014302 -0.093607  0.137064  0.166098  \n",
       "3203  0.072536  0.022610 -0.000515  0.023441 -0.056011  0.031867  0.119171  \n",
       "2207  0.154673  0.173832  0.036977 -0.079820  0.016101  0.155697  0.113778  \n",
       "2278  0.091835  0.029936  0.031678 -0.031677 -0.049278  0.137576  0.009447  \n",
       "3052  0.052678  0.030727 -0.013694  0.004543 -0.065728  0.006634  0.109456  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Собственно классификация. Сначала только для одной семы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT BAD, вроде по убыванию\n",
    "classifier = svm.LinearSVC()\n",
    "classifier3 = svm.SVC(kernel='rbf', gamma='scale', class_weight='balanced', max_iter=3000) \n",
    "classifier8 = svm.LinearSVC(C=0.1, class_weight='balanced', max_iter=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD\n",
    "classifier1 = svm.SVC(kernel='rbf', class_weight='balanced') # хуже\n",
    "classifier2 = svm.SVC(C=0.1, kernel='rbf', class_weight='balanced') # хуже\n",
    "classifier5 = svm.SVC(kernel='poly', degree=2, gamma='scale', class_weight='balanced') # очень плохо\n",
    "classifier6 = svm.SVC(kernel='sigmoid', gamma='scale', class_weight='balanced') # хуже\n",
    "classifier7 = svm.LinearSVC(class_weight='balanced', max_iter=2000) # хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier4 = svm.LinearSVC(C=1.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier4.fit(X_train, y_train)\n",
    "predicted4 = classifier4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       668\n",
      "           1       0.86      0.32      0.46        57\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       725\n",
      "   macro avg       0.90      0.66      0.72       725\n",
      "weighted avg       0.94      0.94      0.93       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.47984019694834457, max:0.6, min:0.30434782608695654, std:0.0889623078072546\n"
     ]
    }
   ],
   "source": [
    "scorer4 = metrics.make_scorer(metrics.f1_score)\n",
    "cv_strategy4 = StratifiedKFold(n_splits=8, shuffle=True, random_state=11)\n",
    "lr_scoring4 = cross_val_score(classifier4, X, y, scoring = scorer4, cv = cv_strategy4)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring4.mean(), lr_scoring4.max(), lr_scoring4.min(), lr_scoring4.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       668\n",
      "           1       0.36      0.67      0.46        57\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       725\n",
      "   macro avg       0.66      0.78      0.70       725\n",
      "weighted avg       0.92      0.88      0.89       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# результаты для третьего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.4588176238945727, max:0.5263157894736843, min:0.3564356435643565, std:0.0457661598609683\n"
     ]
    }
   ],
   "source": [
    "# резульаты для третьего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       668\n",
      "           1       0.86      0.32      0.46        57\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       725\n",
      "   macro avg       0.90      0.66      0.72       725\n",
      "weighted avg       0.94      0.94      0.93       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# результаты для нулевого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.47611470675226614, max:0.6, min:0.30434782608695654, std:0.08825071119361323\n"
     ]
    }
   ],
   "source": [
    "# результаты для нулевого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь массивы:\n",
    "# data = [[вектора для первой семы], [вектора для второй семы], ...]\n",
    "# labels = [[0,0,...], [1,1,...], [2,2,...], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# общая часть\n",
    "scorer = metrics.make_scorer(metrics.f1_score, average='micro')  # specify average here for it not to be 'binary'\n",
    "cv_strategy = StratifiedKFold(n_splits=8, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# общая часть\n",
    "classifier = svm.LinearSVC()\n",
    "classifier3 = svm.SVC(kernel='rbf', gamma='scale', class_weight='balanced', max_iter=3000) \n",
    "classifier8 = svm.LinearSVC(C=0.1, class_weight='balanced', max_iter=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отдельно данные со всеми семами, а не первая VS остальные\n",
    "data = []\n",
    "for sema in dict_for_dom:\n",
    "    data.append(dict_for_dom[sema])\n",
    "\n",
    "labels = []\n",
    "for i, sema in enumerate(dict_for_dom):\n",
    "    labels.append([i]*len(dict_for_dom[sema]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "999\n",
      "2104\n",
      "46\n",
      "23\n",
      "71\n",
      "13\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for element in data:\n",
    "    print(len(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "999\n",
      "2104\n",
      "46\n",
      "23\n",
      "71\n",
      "13\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for el in labels:\n",
    "    print(len(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattend_data = []\n",
    "for vectors_list in data:\n",
    "    flattend_data += vectors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3624"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flattend_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattend_labels = list(flatten_list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3624\n"
     ]
    }
   ],
   "source": [
    "print(len(flattend_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Здесь смотрим на результаты кросс-валидации с разными настройками классификатора "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.6697211651832666, max:0.6873614190687362, min:0.6497797356828194, std:0.013366649484743719\n"
     ]
    }
   ],
   "source": [
    "# для 0 - micro average f1-score\n",
    "lr_scoring = cross_val_score(classifier, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.26102984049097105, max:0.2926829268292683, min:0.22787610619469026, std:0.022293182298738393\n"
     ]
    }
   ],
   "source": [
    "# для 3 \n",
    "lr_scoring = cross_val_score(classifier3, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.6051555095271108, max:0.6263736263736264, min:0.5912087912087912, std:0.012227919872749743\n"
     ]
    }
   ],
   "source": [
    "# для 8\n",
    "lr_scoring = cross_val_score(classifier8, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "А здесь тренируем лучшим классификатором и смотрим на значение метрик для каждого конкретного класса на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattend_data, flattend_labels, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.45      0.53        82\n",
      "           1       0.54      0.49      0.51       298\n",
      "           2       0.72      0.85      0.78       639\n",
      "           3       0.00      0.00      0.00        10\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00        20\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      1088\n",
      "   macro avg       0.24      0.22      0.23      1088\n",
      "weighted avg       0.62      0.67      0.64      1088\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для значений главы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# значений - 4\n",
    "# словарь, в котором ключи - встречающиеся семы, значение - лист с векторами\n",
    "dict_for_glava = dict()\n",
    "for entity in contexts_dict[\"glava\"]:\n",
    "    dict_for_glava.setdefault(entity.sem_set, [])\n",
    "    dict_for_glava[entity.sem_set].append(entity.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r-concr_der-shift_dt-partb'} 139\n",
      "{'r-concr_pt-partb_pc-hum'} 8\n",
      "{'r-concr_t-hum'} 311\n",
      "{'r-concr_t-text_pt-part_pc-text'} 275\n"
     ]
    }
   ],
   "source": [
    "for key in dict_for_glava:\n",
    "    print(key, len(dict_for_glava[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sema in dict_for_glava:\n",
    "    data.append(dict_for_glava[sema])\n",
    "\n",
    "labels = []\n",
    "for i, sema in enumerate(dict_for_glava):\n",
    "    labels.append([i]*len(dict_for_glava[sema]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattend_data = []\n",
    "for vectors_list in data:\n",
    "    flattend_data += vectors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattend_labels = list(flatten_list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.766768580881484, max:0.8131868131868132, min:0.7252747252747253, std:0.028206760449533155\n"
     ]
    }
   ],
   "source": [
    "# для 0 - micro average f1-score\n",
    "lr_scoring = cross_val_score(classifier, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.5771131198550554, max:0.6222222222222222, min:0.5164835164835165, std:0.0320968957602986\n"
     ]
    }
   ],
   "source": [
    "# для 3 \n",
    "lr_scoring = cross_val_score(classifier3, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.7776994958446571, max:0.8021978021978022, min:0.7634408602150536, std:0.012914587953852913\n"
     ]
    }
   ],
   "source": [
    "# для 8\n",
    "lr_scoring = cross_val_score(classifier8, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattend_data, flattend_labels, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64        40\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.82      0.78      0.80        95\n",
      "           3       0.79      0.93      0.86        83\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       220\n",
      "   macro avg       0.83      0.70      0.74       220\n",
      "weighted avg       0.79      0.80      0.79       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier8.fit(X_train, y_train)\n",
    "predicted = classifier8.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для значений лука"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# значений - 2\n",
    "dict_for_luk = dict()\n",
    "for entity in contexts_dict[\"luk\"]:\n",
    "    dict_for_luk.setdefault(entity.sem_set, [])\n",
    "    dict_for_luk[entity.sem_set].append(entity.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r-concr_t-plant_t-fruit_t-food_pt-aggr'} 1976\n",
      "{'r-concr_t-tool-weapon_top-arc'} 662\n"
     ]
    }
   ],
   "source": [
    "for key in dict_for_luk:\n",
    "    print(key, len(dict_for_luk[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sema in dict_for_luk:\n",
    "    data.append(dict_for_luk[sema])\n",
    "\n",
    "labels = []\n",
    "for i, sema in enumerate(dict_for_luk):\n",
    "    labels.append([i]*len(dict_for_luk[sema]))\n",
    "\n",
    "flattend_data = []\n",
    "for vectors_list in data:\n",
    "    flattend_data += vectors_list    \n",
    "\n",
    "flattend_labels = list(flatten_list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.9454038868932486, max:0.9636363636363636, min:0.9209726443768997, std:0.011700631422731686\n"
     ]
    }
   ],
   "source": [
    "# для 0 - micro average f1-score\n",
    "lr_scoring = cross_val_score(classifier, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.9074940130791194, max:0.9272727272727272, min:0.8848484848484849, std:0.016324960022168142\n"
     ]
    }
   ],
   "source": [
    "# для 3 \n",
    "lr_scoring = cross_val_score(classifier3, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.9336603113198858, max:0.9484848484848485, min:0.9212121212121213, std:0.008907821206948005\n"
     ]
    }
   ],
   "source": [
    "# для 8\n",
    "lr_scoring = cross_val_score(classifier8, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattend_data, flattend_labels, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       599\n",
      "           1       0.88      0.88      0.88       193\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       792\n",
      "   macro avg       0.92      0.92      0.92       792\n",
      "weighted avg       0.94      0.94      0.94       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для значений органа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r-concr_der-shift_dt-partb'} 12\n",
      "{'r-concr_pt-partb_pc-hum_pc-animal_hi-class'} 170\n",
      "{'r-concr_t-org_hi-class'} 923\n",
      "{'r-concr_t-tool-mus'} 30\n"
     ]
    }
   ],
   "source": [
    "# значений - 4\n",
    "# словарь, в котором ключи - встречающиеся семы, значение - лист с векторами\n",
    "dict_for_organ = dict()\n",
    "for entity in contexts_dict[\"organ\"]:\n",
    "    dict_for_organ.setdefault(entity.sem_set, [])\n",
    "    dict_for_organ[entity.sem_set].append(entity.vector)\n",
    "\n",
    "for key in dict_for_organ:\n",
    "    print(key, len(dict_for_organ[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sema in dict_for_organ:\n",
    "    data.append(dict_for_organ[sema])\n",
    "\n",
    "labels = []\n",
    "for i, sema in enumerate(dict_for_organ):\n",
    "    labels.append([i]*len(dict_for_organ[sema]))\n",
    "\n",
    "flattend_data = []\n",
    "for vectors_list in data:\n",
    "    flattend_data += vectors_list    \n",
    "\n",
    "flattend_labels = list(flatten_list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.9295865973191229, max:0.9574468085106385, min:0.8680555555555556, std:0.026612554083787477\n"
     ]
    }
   ],
   "source": [
    "# для 0 - micro average f1-score\n",
    "lr_scoring = cross_val_score(classifier, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.8255338698485613, max:0.8723404255319149, min:0.8014184397163121, std:0.024681661831673626\n"
     ]
    }
   ],
   "source": [
    "# для 3 \n",
    "lr_scoring = cross_val_score(classifier3, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.9241936512506073, max:0.9513888888888888, min:0.9027777777777778, std:0.015713531998846807\n"
     ]
    }
   ],
   "source": [
    "# для 8\n",
    "lr_scoring = cross_val_score(classifier8, flattend_data, flattend_labels, scoring = scorer, cv = cv_strategy)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.79      0.76      0.78        55\n",
      "           2       0.95      0.97      0.96       279\n",
      "           3       1.00      0.40      0.57         5\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       341\n",
      "   macro avg       0.69      0.53      0.58       341\n",
      "weighted avg       0.92      0.92      0.92       341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattend_data, flattend_labels, test_size=0.3, random_state=11)\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для значений вида "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r-abstr_der-shift'} 1150\n",
      "{'r-abstr_r-concr_pt-set_sc-X'} 656\n",
      "{'r-abstr_t-ment'} 13\n",
      "{'r-abstr_t-perc_der-v'} 1191\n",
      "{'r-concr_t-doc'} 7\n",
      "{'r-concr_t-workart'} 10\n"
     ]
    }
   ],
   "source": [
    "# значений - 6\n",
    "# словарь, в котором ключи - встречающиеся семы, значение - лист с векторами\n",
    "dict_for_vid = dict()\n",
    "for entity in contexts_dict[\"vid\"]:\n",
    "    dict_for_vid.setdefault(entity.sem_set, [])\n",
    "    dict_for_vid[entity.sem_set].append(entity.vector)\n",
    "\n",
    "for key in dict_for_vid:\n",
    "    print(key, len(dict_for_vid[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sema in dict_for_vid:\n",
    "    data.append(dict_for_vid[sema])\n",
    "\n",
    "labels = []\n",
    "for i, sema in enumerate(dict_for_vid):\n",
    "    labels.append([i]*len(dict_for_vid[sema]))\n",
    "\n",
    "flattend_data = []\n",
    "for vectors_list in data:\n",
    "    flattend_data += vectors_list    \n",
    "\n",
    "flattend_labels = list(flatten_list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вынуждены написать заново и изменить количество сплитов: их было 8, а в одном классе < 8 инстансов\n",
    "scorer_vid = metrics.make_scorer(metrics.f1_score, average='micro')  # specify average here for it not to be 'binary'\n",
    "cv_strategy_vid = StratifiedKFold(n_splits=6, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.7277202331967865, max:0.7598425196850394, min:0.7111553784860557, std:0.01722749517254849\n"
     ]
    }
   ],
   "source": [
    "# для 0 - micro average f1-score\n",
    "lr_scoring = cross_val_score(classifier, flattend_data, flattend_labels, scoring = scorer_vid, cv = cv_strategy_vid)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.5480939158184526, max:0.5634920634920635, min:0.5197628458498024, std:0.014121923119055106\n"
     ]
    }
   ],
   "source": [
    "# для 3 \n",
    "lr_scoring = cross_val_score(classifier3, flattend_data, flattend_labels, scoring = scorer_vid, cv = cv_strategy_vid)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log mean:0.7237971531364235, max:0.7480314960629921, min:0.7023809523809523, std:0.014870203881450111\n"
     ]
    }
   ],
   "source": [
    "# для 8\n",
    "lr_scoring = cross_val_score(classifier8, flattend_data, flattend_labels, scoring = scorer_vid, cv = cv_strategy_vid)\n",
    "print('Log mean:%s, max:%s, min:%s, std:%s'%(lr_scoring.mean(), lr_scoring.max(), lr_scoring.min(), lr_scoring.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.68       325\n",
      "           1       0.69      0.62      0.65       210\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.74      0.79      0.77       365\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       909\n",
      "   macro avg       0.35      0.35      0.35       909\n",
      "weighted avg       0.70      0.71      0.70       909\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boss\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flattend_data, flattend_labels, test_size=0.3, random_state=11)\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
